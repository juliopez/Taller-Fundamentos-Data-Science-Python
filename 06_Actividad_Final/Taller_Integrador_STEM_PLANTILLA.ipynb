{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/juliopez/Taller-Fundamentos-Data-Science-Python/blob/main/06_Actividad_Final/Taller_Integrador_STEM_PLANTILLA.ipynb)"
      ],
      "metadata": {
        "id": "b-IXBM6IuwXb"
      },
      "id": "b-IXBM6IuwXb"
    },
    {
      "cell_type": "markdown",
      "id": "f3cf1308",
      "metadata": {
        "id": "f3cf1308"
      },
      "source": [
        "# Taller integrador – Notebook de trabajo  \n",
        "**Curso:** Fundamentos de Data Science con Python  \n",
        "**Sesión 6 – Taller integrador**  \n",
        "\n",
        "En este notebook trabajarás en grupo para desarrollar el taller:\n",
        "\n",
        "1. Cargar y explorar el dataset  \n",
        "2. Limpiar y preprocesar los datos  \n",
        "3. Realizar un análisis exploratorio (EDA) con visualizaciones  \n",
        "4. Preparar los datos para modelar  \n",
        "5. Implementar y entrenar una red neuronal MLP (obligatoria)  \n",
        "6. Evaluar el modelo y extraer conclusiones  \n",
        "7. Redactar una breve reflexión ética  \n",
        "\n",
        "> **Nota:** Este notebook es una **plantilla**. Completa cada sección con tu propio código y comentarios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce49b0b4",
      "metadata": {
        "id": "ce49b0b4"
      },
      "source": [
        "## 1. Importar librerías y cargar el dataset  \n",
        "\n",
        "- Importa las librerías que necesitas (pandas, numpy, matplotlib, scikit-learn, keras, etc.).  \n",
        "- Carga el archivo `datos_taller_integrador_STEM.csv`.  \n",
        "- Muestra las primeras filas para tener una idea general del contenido.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c4398a",
      "metadata": {
        "id": "65c4398a"
      },
      "outputs": [],
      "source": [
        "# TODO: importar librerías principales\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sugerencia: puedes necesitar también:\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "# from sklearn.impute import SimpleImputer\n",
        "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "# TODO: cargar el dataset\n",
        "ruta = \"datos_taller_integrador_STEM.csv\"  # ajustar ruta si es necesario\n",
        "df = pd.read_csv(ruta)\n",
        "\n",
        "# TODO: mostrar las primeras filas\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84df1699",
      "metadata": {
        "id": "84df1699"
      },
      "source": [
        "## 2. Exploración inicial de los datos  \n",
        "\n",
        "Objetivo: obtener una visión general de la estructura del dataset.\n",
        "\n",
        "- Revisa el número de filas y columnas.  \n",
        "- Inspecciona los tipos de datos.  \n",
        "- Obtén un resumen estadístico de las variables numéricas y categóricas.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc6b80e",
      "metadata": {
        "id": "9cc6b80e"
      },
      "outputs": [],
      "source": [
        "# TODO: tamaño del dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0fe3820",
      "metadata": {
        "id": "a0fe3820"
      },
      "outputs": [],
      "source": [
        "# TODO: información general de tipos de datos y valores nulos\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a705706",
      "metadata": {
        "id": "4a705706"
      },
      "outputs": [],
      "source": [
        "# TODO: resumen descriptivo (numérico y, si quieres, categórico)\n",
        "df.describe(include=\"all\").T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52995afa",
      "metadata": {
        "id": "52995afa"
      },
      "source": [
        "## 3. Limpieza y preprocesamiento de los datos  \n",
        "\n",
        "En el diccionario de datos se indicó que el dataset contiene:\n",
        "\n",
        "- Valores faltantes  \n",
        "- Outliers (horas de estudio, asistencia, edad, etc.)  \n",
        "- Valores categóricos inconsistentes (por ejemplo, distintas formas de escribir la misma categoría)  \n",
        "- Valores fuera de dominio (por ejemplo, 0/5 en nivel de álgebra, 2 en uso de plataforma, etc.)  \n",
        "\n",
        "**Tareas sugeridas:**\n",
        "\n",
        "1. Detectar los problemas más evidentes en cada variable.  \n",
        "2. Decidir una estrategia de tratamiento (corregir, imputar, recodificar, truncar, etc.).  \n",
        "3. Aplicar las transformaciones y documentar tus decisiones en comentarios.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04cdc610",
      "metadata": {
        "id": "04cdc610"
      },
      "source": [
        "### 3.1 Ejemplo: revisar variables categóricas (`sexo`, `dependencia_colegio`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2a9778",
      "metadata": {
        "id": "cd2a9778"
      },
      "outputs": [],
      "source": [
        "# TODO: revisar distribución de 'sexo'\n",
        "df['sexo'].value_counts(dropna=False)\n",
        "\n",
        "# TODO: decidir qué hacer con valores como 'No responde' o 'X' y aplicar la transformación correspondiente\n",
        "# df['sexo'] = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dfa3723",
      "metadata": {
        "id": "3dfa3723"
      },
      "outputs": [],
      "source": [
        "# TODO: revisar distribución de 'dependencia_colegio'\n",
        "df['dependencia_colegio'].value_counts(dropna=False)\n",
        "\n",
        "# TODO: unificar formato (minúsculas, mayúsculas) y recodificar categorías de forma consistente\n",
        "# df['dependencia_colegio'] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42001eeb",
      "metadata": {
        "id": "42001eeb"
      },
      "source": [
        "### 3.2 Revisar y corregir variables numéricas (`nivel_algebra`, `horas_estudio_semanal`, `asistencia_porcentaje`, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6367b87f",
      "metadata": {
        "id": "6367b87f"
      },
      "outputs": [],
      "source": [
        "# TODO: revisar valores únicos de nivel_algebra\n",
        "df['nivel_algebra'].value_counts(dropna=False)\n",
        "\n",
        "# TODO: convertir valores fuera de [1, 2, 3, 4] en NaN o corregir según criterio\n",
        "# df.loc[...] = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787c951c",
      "metadata": {
        "id": "787c951c"
      },
      "outputs": [],
      "source": [
        "# TODO: revisar distribución de horas_estudio_semanal\n",
        "df['horas_estudio_semanal'].describe()\n",
        "\n",
        "# TODO: tratar valores negativos o muy altos\n",
        "# df.loc[...] = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca80944a",
      "metadata": {
        "id": "ca80944a"
      },
      "outputs": [],
      "source": [
        "# TODO: revisar distribución de asistencia_porcentaje\n",
        "df['asistencia_porcentaje'].describe()\n",
        "\n",
        "# TODO: truncar o corregir valores fuera de [0, 100]\n",
        "# df.loc[...] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49b20f2e",
      "metadata": {
        "id": "49b20f2e"
      },
      "source": [
        "### 3.3 Resumen de valores faltantes después de tus correcciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d57befc",
      "metadata": {
        "id": "3d57befc"
      },
      "outputs": [],
      "source": [
        "# TODO: calcular proporción de valores faltantes por columna\n",
        "df.isna().mean().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f9157a",
      "metadata": {
        "id": "37f9157a"
      },
      "source": [
        "## 4. Análisis exploratorio de datos (EDA)  \n",
        "\n",
        "Realiza un EDA que te permita responder preguntas como:\n",
        "\n",
        "- ¿Cómo se distribuye la `nota_final`?  \n",
        "- ¿Cuál es la proporción de estudiantes que aprueban?  \n",
        "- ¿Cómo se relaciona la nota de diagnóstico con la nota final?  \n",
        "- ¿Hay diferencias en la nota final según la dependencia de colegio u otras variables?  \n",
        "\n",
        "Incluye al menos **3 visualizaciones** (histogramas, boxplots, scatter plots, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f041146",
      "metadata": {
        "id": "3f041146"
      },
      "outputs": [],
      "source": [
        "# TODO: distribución de la nota final\n",
        "# Ejemplo:\n",
        "# plt.figure()\n",
        "# df['nota_final'].hist(bins=20)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16426089",
      "metadata": {
        "id": "16426089"
      },
      "outputs": [],
      "source": [
        "# TODO: proporción de estudiantes que aprueban/reprueban\n",
        "# df['aprueba'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "134afcf8",
      "metadata": {
        "id": "134afcf8"
      },
      "outputs": [],
      "source": [
        "# TODO: relación entre nota_diagnostico_matematica y nota_final (scatter)\n",
        "# plt.figure()\n",
        "# plt.scatter(df['nota_diagnostico_matematica'], df['nota_final'])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f05639",
      "metadata": {
        "id": "38f05639"
      },
      "outputs": [],
      "source": [
        "# TODO: nota_final por alguna variable categórica (por ejemplo, dependencia_colegio)\n",
        "# df.boxplot(column='nota_final', by='dependencia_colegio', rot=45)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70b01f09",
      "metadata": {
        "id": "70b01f09"
      },
      "source": [
        "## 5. Preparación de datos para el modelo MLP  \n",
        "\n",
        "En este taller utilizaremos como **variable objetivo** la columna `aprueba` (clasificación binaria).  \n",
        "\n",
        "**Pasos sugeridos:**\n",
        "\n",
        "1. Seleccionar las variables que usarás como *features* (X).  \n",
        "2. Separar X (features) e y (target).  \n",
        "3. Identificar columnas numéricas y categóricas.  \n",
        "4. Definir un `ColumnTransformer` con:\n",
        "   - Imputación + estandarización para variables numéricas.  \n",
        "   - Imputación + One-Hot Encoding para variables categóricas.  \n",
        "5. Dividir en conjuntos de entrenamiento y prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c994f61",
      "metadata": {
        "id": "0c994f61"
      },
      "outputs": [],
      "source": [
        "# TODO: definir lista de columnas de entrada\n",
        "features = [\n",
        "    'sexo',\n",
        "    'edad',\n",
        "    'dependencia_colegio',\n",
        "    'nota_diagnostico_matematica',\n",
        "    'nivel_algebra',\n",
        "    'promedio_lab_fisica',\n",
        "    'quizzes_estadistica',\n",
        "    'horas_estudio_semanal',\n",
        "    'asistencia_porcentaje',\n",
        "    'participacion_clases',\n",
        "    'entregas_atrasadas',\n",
        "    'uso_plataforma_aprendizaje',\n",
        "    'asiste_tutorias'\n",
        "]\n",
        "\n",
        "X = df[features].copy()\n",
        "y = df['aprueba'].copy()\n",
        "\n",
        "# TODO: identificar columnas numéricas y categóricas\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "num_cols, cat_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc0f61be",
      "metadata": {
        "id": "fc0f61be"
      },
      "outputs": [],
      "source": [
        "# TODO: construir preprocesador (ColumnTransformer) con pipelines numéricos y categóricos\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.impute import SimpleImputer\n",
        "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# numeric_transformer = Pipeline(steps=[\n",
        "#     ('imputer', SimpleImputer(strategy='median')),\n",
        "#     ('scaler', StandardScaler())\n",
        "# ])\n",
        "\n",
        "# categorical_transformer = Pipeline(steps=[\n",
        "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "# ])\n",
        "\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('num', numeric_transformer, num_cols),\n",
        "#         ('cat', categorical_transformer, cat_cols)\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# TODO: dividir en train/test, ajustar el preprocesador y transformar los datos\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
        "\n",
        "# X_train_prep = preprocessor.fit_transform(X_train)\n",
        "# X_test_prep = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb136fc",
      "metadata": {
        "id": "2bb136fc"
      },
      "source": [
        "## 6. Implementación de la red neuronal MLP (obligatoria)  \n",
        "\n",
        "Recuerda los elementos básicos vistos en la sesión de redes neuronales:\n",
        "\n",
        "- Capa de entrada con tantas neuronas como columnas de X transformada.  \n",
        "- Una o dos capas ocultas con activación ReLU.  \n",
        "- Capa de salida con activación sigmoide (para clasificación binaria).  \n",
        "- Función de pérdida: `binary_crossentropy`.  \n",
        "- Optimizador: `adam`.  \n",
        "\n",
        "Entrena el modelo (por ejemplo, 20–50 épocas) y registra las métricas.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d61509",
      "metadata": {
        "id": "f3d61509"
      },
      "outputs": [],
      "source": [
        "# TODO: construir el modelo MLP usando Keras\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "# input_dim = X_train_prep.shape[1]\n",
        "\n",
        "# model = keras.Sequential([\n",
        "#     layers.Input(shape=(input_dim,)),\n",
        "#     layers.Dense(16, activation='relu'),\n",
        "#     layers.Dense(8, activation='relu'),\n",
        "#     layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss='binary_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4118c66",
      "metadata": {
        "id": "f4118c66"
      },
      "outputs": [],
      "source": [
        "# TODO: entrenar el modelo y guardar el historial\n",
        "# history = model.fit(\n",
        "#     X_train_prep, y_train,\n",
        "#     validation_split=0.2,\n",
        "#     epochs=30,\n",
        "#     batch_size=32,\n",
        "#     verbose=1\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f5f2f6b",
      "metadata": {
        "id": "0f5f2f6b"
      },
      "source": [
        "### 6.1 Curvas de entrenamiento  \n",
        "\n",
        "Grafica la evolución de la pérdida y de la exactitud para entrenamiento y validación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5c9750",
      "metadata": {
        "id": "8b5c9750"
      },
      "outputs": [],
      "source": [
        "# TODO: graficar curvas de pérdida y exactitud\n",
        "# plt.figure()\n",
        "# plt.plot(history.history['loss'], label='loss')\n",
        "# plt.plot(history.history['val_loss'], label='val_loss')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(history.history['accuracy'], label='acc')\n",
        "# plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c5faf0d",
      "metadata": {
        "id": "0c5faf0d"
      },
      "source": [
        "## 7. Evaluación del modelo  \n",
        "\n",
        "- Calcula accuracy en el conjunto de prueba.  \n",
        "- Obtén la matriz de confusión.  \n",
        "- Genera un `classification_report`.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c50bad5e",
      "metadata": {
        "id": "c50bad5e"
      },
      "outputs": [],
      "source": [
        "# TODO: evaluar el modelo en el conjunto de prueba\n",
        "# y_pred_proba = model.predict(X_test_prep).ravel()\n",
        "# y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "\n",
        "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# acc = accuracy_score(y_test, y_pred)\n",
        "# cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# print('Accuracy:', acc)\n",
        "# print('Matriz de confusión:\\n', cm)\n",
        "# print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e86d7d",
      "metadata": {
        "id": "a0e86d7d"
      },
      "source": [
        "## 8. Comentarios finales y reflexión ética  \n",
        "\n",
        "En esta sección, discutan en grupo:\n",
        "\n",
        "- ¿Qué variables parecen tener mayor peso en la predicción de aprobación?  \n",
        "- ¿Qué riesgos existen al usar modelos como este para tomar decisiones sobre estudiantes?  \n",
        "- ¿Qué tipo de sesgos podrían introducirse si se usan variables como sexo o dependencia del colegio?  \n",
        "- ¿Cómo debería complementarse este tipo de modelo con el criterio pedagógico del docente?  \n",
        "\n",
        "Escribe aquí un breve párrafo con las conclusiones de tu grupo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ed2ade",
      "metadata": {
        "id": "e1ed2ade"
      },
      "outputs": [],
      "source": [
        "# TODO: redactar comentarios finales y reflexión ética (como texto multilínea)\n",
        "comentarios_finales = \"\"\"\n",
        "Escribe aquí las conclusiones de tu grupo sobre el desempeño del modelo,\n",
        "sus limitaciones y las implicancias éticas de su uso en contextos educativos.\n",
        "\"\"\"\n",
        "\n",
        "print(comentarios_finales)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}