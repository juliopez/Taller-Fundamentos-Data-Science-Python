{"cells":[{"cell_type":"markdown","id":"e4cf59d6","metadata":{"id":"e4cf59d6"},"source":["\n","# üéØ Actividad Pr√°ctica ‚Äî Sesi√≥n 5 (45‚Äì50 min)\n","\n","**Duraci√≥n total sugerida:** 50‚Äì60 min\n"]},{"cell_type":"markdown","source":["> üìù **Nota :**  \n","> El c√≥digo que se muestra a continuaci√≥n est√° intencionadamente presentado en **celdas de texto (Markdown)**.  \n","> La idea es que usted pueda **copiarlo, adaptarlo y crear su propio notebook**, tomando decisiones sobre la estructura de la CNN y los hiperpar√°metros.  \n",">\n","> Este enfoque busca promover la comprensi√≥n profunda del modelo y no solo su ejecuci√≥n.\n","\n","Este ejercicio busca que usted analice la arquitectura de una CNN simple y explore c√≥mo los hiperpar√°metros afectan su comportamiento.\n"],"metadata":{"id":"aMwtM6zw8Oi2"},"id":"aMwtM6zw8Oi2"},{"cell_type":"markdown","source":["## PARTE 1: Entendiendo una CNN simple y sus hiperpar√°metros"],"metadata":{"id":"lFJQNPNpAurJ"},"id":"lFJQNPNpAurJ"},{"cell_type":"markdown","source":["En esta primera parte construiremos una CNN peque√±a utilizando el dataset MNIST.\n","El objetivo es comprender la estructura b√°sica de una red convolucional y reflexionar sobre el impacto de modificar sus hiperpar√°metros.\n","\n","```python\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist\n","\n","# Cargar datos MNIST\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Normalizar y adaptar formato (28x28x1)\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test  = x_test.astype(\"float32\") / 255.0\n","\n","# A√±adir dimensi√≥n de canal (blanco y negro)\n","x_train = x_train[..., tf.newaxis]   # (60000, 28, 28, 1)\n","x_test  = x_test[..., tf.newaxis]\n","\n","num_clases = 10\n","\n","\n"],"metadata":{"id":"Z3DihEbH1Cxx"},"id":"Z3DihEbH1Cxx"},{"cell_type":"markdown","source":["### Ahora que tenemos los datos listos, construiremos una CNN simple para identificar sus partes fundamentales y sus respectivos hiperpar√°metros modificables.\n","```python\n","# MODELO CNN SIMPLE\n","modelo_cnn = models.Sequential([\n","    # Capa convolucional 1\n","    layers.Conv2D(\n","        filters=32,          # ‚Üê hiperpar√°metro 1\n","        kernel_size=(3, 3),  # ‚Üê hiperpar√°metro 2\n","        activation=\"relu\",\n","        input_shape=(28, 28, 1)\n","    ),\n","    layers.MaxPooling2D(pool_size=(2, 2)),  # ‚Üê hiperpar√°metro 3\n","\n","    # Capa convolucional 2\n","    layers.Conv2D(\n","        filters=64,          # ‚Üê hiperpar√°metro 4\n","        kernel_size=(3, 3),\n","        activation=\"relu\"\n","    ),\n","    layers.MaxPooling2D(pool_size=(2, 2)),\n","\n","    layers.Flatten(),\n","\n","    layers.Dense(64, activation=\"relu\"),     # ‚Üê hiperpar√°metro 5 (n√∫mero de neuronas)\n","    layers.Dense(num_clases, activation=\"softmax\")\n","])\n","\n","# Compilaci√≥n del modelo\n","modelo_cnn.compile(\n","    optimizer=\"adam\",\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Resumen de la arquitectura\n","modelo_cnn.summary()\n"],"metadata":{"id":"n9j1nPcT4YaH"},"id":"n9j1nPcT4YaH"},{"cell_type":"markdown","source":["### La siguiente secci√≥n permite configurar la cantidad de iteraciones (√©pocas) que ejecutar√° el modelo.\n","\n","```python\n","historial = modelo_cnn.fit(\n","    x_train, y_train,\n","    epochs=2,              # ‚Üê hiperpar√°metro 6\n","    batch_size=128,        # ‚Üê hiperpar√°metro 7\n","    validation_split=0.1,\n","    verbose=1\n",")\n"],"metadata":{"id":"snDhWIdZ5Qy_"},"id":"snDhWIdZ5Qy_"},{"cell_type":"markdown","source":["###Considerando solo la vista -y no ejecucion del codigo - reflexione a partir de la sig uiente pregunta:  ¬øQu√© cree que pasar√≠a si‚Ä¶?\n","\n","* Duplicamos filters en la primera capa de 32 ‚Üí 64.\n","\n","* Quitamos una capa de MaxPooling2D.\n","\n","* Aumentamos kernel_size de (3,3) a (5,5).\n","\n","* Aumentamos la capa densa final de 64 ‚Üí 256 neuronas.\n","\n","* Aumentamos epochs de 2 ‚Üí 10.\n","\n","### ¬øC√≥mo cree que cambiar√≠a‚Ä¶?\n","\n","* El tiempo de entrenamiento.\n","\n","* El riesgo de sobreajuste (overfitting).\n","\n","* La capacidad del modelo para aprender patrones m√°s complejos."],"metadata":{"id":"7Uy6YCte6IM5"},"id":"7Uy6YCte6IM5"},{"cell_type":"markdown","source":["### Modifique 1 o 2 hyperparametros y ejecute el entrenamiento muy breve (1‚Äì2 epochs).\n","\n","* Compare el accuracy y el tiempo de entrenamiento."],"metadata":{"id":"rqduyH2u7I4D"},"id":"rqduyH2u7I4D"},{"cell_type":"markdown","source":["### Glosario de Hiperpar√°metros\n","\n","A continuaci√≥n se describen los principales hiperpar√°metros utilizados en la CNN simple construida en esta actividad:\n","\n","**1. `filters`**  \n","N√∫mero de filtros (o kernels) en una capa convolucional.  \n","M√°s filtros permiten detectar m√°s tipos de patrones, pero aumentan el costo computacional y el riesgo de sobreajuste.\n","\n","**2. `kernel_size`**  \n","Tama√±o del filtro que ‚Äúrecorre‚Äù la imagen (ej.: 3√ó3, 5√ó5).  \n","Un kernel m√°s grande capta patrones m√°s amplios, pero puede perder detalle y hacer el modelo m√°s lento.\n","\n","**3. `pool_size`**  \n","Tama√±o de la ventana usada en MaxPooling.  \n","Reduce la dimensi√≥n espacial del mapa de caracter√≠sticas, haciendo el modelo m√°s eficiente y menos propenso al sobreajuste.\n","\n","**4. `filters` (segunda capa)**  \n","Igual que el hiperpar√°metro 1, pero en una capa m√°s profunda.  \n","Generalmente se aumenta (32‚Üí64‚Üí128) para aprender patrones m√°s complejos.\n","\n","**5. `units` en `Dense`**  \n","N√∫mero de neuronas en la capa completamente conectada.  \n","M√°s neuronas permiten representar relaciones m√°s complejas, pero incrementan el riesgo de sobreajuste.\n","\n","**6. `epochs`**  \n","Cantidad de pasadas completas por todo el conjunto de entrenamiento.  \n","M√°s √©pocas permiten aprender m√°s, pero pueden llevar a sobreentrenamiento.\n","\n","**7. `batch_size`**  \n","Cantidad de muestras procesadas por el modelo en cada actualizaci√≥n de par√°metros.  \n","Batches peque√±os ‚Üí aprendizaje m√°s ruidoso pero potencialmente mejor generalizaci√≥n.  \n","Batches grandes ‚Üí entrenamiento m√°s estable y r√°pido, pero con riesgo de sobreajuste.\n"],"metadata":{"id":"046mGsWY_aBK"},"id":"046mGsWY_aBK"},{"cell_type":"markdown","source":["## PARTE 2: Explorando EfficientNetB0 y sus hiperpar√°metros"],"metadata":{"id":"ZylpuaKTAjqz"},"id":"ZylpuaKTAjqz"},{"cell_type":"markdown","source":["En esta segunda parte trabajaremos con **EfficientNetB0**, un modelo moderno de *Transfer Learning* entrenado originalmente sobre el dataset ImageNet.\n","\n","El objetivo es identificar sus componentes principales, reconocer los hiperpar√°metros m√°s relevantes y reflexionar sobre c√≥mo estos afectan el comportamiento del modelo.\n","\n","> üìù Nota para participantes  \n","> Al igual que en la secci√≥n anterior, el siguiente c√≥digo se presenta en formato de texto (Markdown).  \n","> Se espera que usted **cree su propio notebook** y copie, adapte o modifique este modelo seg√∫n los cambios que desee explorar."],"metadata":{"id":"e7emvUxTBlNc"},"id":"e7emvUxTBlNc"},{"cell_type":"markdown","source":["### Paso 1: Cargar EfficientNetB0 preentrenado\n","\n","```python\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras import layers, models, optimizers\n","\n","# Cargar EfficientNetB0 sin la parte final (include_top=False)\n","base_model = EfficientNetB0(\n","    weights=\"imagenet\",\n","    include_top=False,\n","    input_shape=(224, 224, 3)    # ‚Üê hiperpar√°metro 1 (tama√±o de entrada)\n",")\n","\n","# Congelar la base convolucional (no se entrena)\n","base_model.trainable = False      # ‚Üê hiperpar√°metro 2 (capas entrenables)\n"],"metadata":{"id":"0ZIrVs3cBfU3"},"id":"0ZIrVs3cBfU3"},{"cell_type":"markdown","source":["### Paso 2: Crear un nuevo clasificador final\n","```python\n","inputs = layers.Input(shape=(224, 224, 3))\n","x = base_model(inputs, training=False)\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.2)(x)        # ‚Üê hiperpar√°metro 3 (tasa de dropout)\n","outputs = layers.Dense(5, activation=\"softmax\")(x)   # ‚Üê hiperpar√°metro 4 (n√∫mero de clases)\n","\n","modelo_eff = models.Model(inputs, outputs)\n"],"metadata":{"id":"Vrm7hv4VB4GF"},"id":"Vrm7hv4VB4GF"},{"cell_type":"markdown","source":["### Paso 3: Compilar el modelo\n","```python\n","modelo_eff.compile(\n","    optimizer=optimizers.Adam(learning_rate=1e-3),  # ‚Üê hiperpar√°metro 5 (learning rate)\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","modelo_eff.summary()\n"],"metadata":{"id":"qZaU_M_dCD6t"},"id":"qZaU_M_dCD6t"},{"cell_type":"markdown","source":["### Sin ejecutar el c√≥digo, reflexione a partir de la siguiente pregunta: ¬øQu√© cree que ocurrir√≠a si‚Ä¶?\n","\n","* Cambiamos input_shape de (224,224,3) a (128,128,3).\n","\n","* Descongelamos parcialmente la base (base_model.trainable = True).\n","\n","* Aumentamos el Dropout de 0.2 a 0.5.\n","\n","* Cambiamos la tasa de aprendizaje de 1e-3 a 1e-5.\n","\n","* Aumentamos la capa final de 5 a 10 clases.\n","\n","### ¬øC√≥mo cree que cambiar√≠an‚Ä¶?\n","\n","* El tiempo de entrenamiento.\n","\n","* El riesgo de sobreajuste (overfitting).\n","\n","* La capacidad del modelo para generalizar.\n","\n","* La estabilidad del gradiente al entrenar."],"metadata":{"id":"1sr5jtaFCs8R"},"id":"1sr5jtaFCs8R"},{"cell_type":"markdown","source":["### Glosario de Hiperpar√°metros en EfficientNetB0\n","\n","A continuaci√≥n se describen los hiperpar√°metros principales utilizados en el modelo EfficientNetB0 presentado en esta actividad:\n","\n","**1. `input_shape`**  \n","Dimensi√≥n de entrada esperada por el modelo (ej.: 224√ó224√ó3).  \n","Controla cu√°nto debe redimensionarse cada imagen antes de entrar a la red.  \n","Tama√±os menores reducen el costo computacional pero pueden perder detalle importante.\n","\n","**2. `base_model.trainable`**  \n","Indica si las capas convolucionales preentrenadas pueden actualizarse durante el entrenamiento.  \n","- `False` ‚Üí solo se entrena la \"cabeza\" final (m√°s r√°pido y estable).  \n","- `True` ‚Üí se ajustan todas las capas (mayor capacidad, pero tambi√©n mayor riesgo de sobreajuste y necesidad de datos).\n","\n","**3. `Dropout`**  \n","Fracci√≥n de neuronas que se ‚Äúapagan‚Äù aleatoriamente durante el entrenamiento.  \n","Ayuda a prevenir sobreajuste, especialmente en modelos grandes.\n","\n","**4. `Dense(units)` (n√∫mero de clases)**  \n","Cantidad de neuronas en la capa final.  \n","Debe coincidir con el n√∫mero de clases a predecir.  \n","Un n√∫mero mayor no implica necesariamente mejor rendimiento.\n","\n","**5. `learning_rate`**  \n","Velocidad con la que se actualizan los pesos del modelo durante el entrenamiento.  \n","- Valores altos ‚Üí aprendizaje r√°pido pero inestable.  \n","- Valores muy bajos ‚Üí aprendizaje lento y posible estancamiento.\n","\n","**6. `optimizer`** (Adam en este caso)  \n","Algoritmo que ajusta los pesos para minimizar la funci√≥n de p√©rdida.  \n","Adam combina ventajas de AdaGrad y RMSProp y funciona bien en la mayor√≠a de problemas.\n","\n","**7. `GlobalAveragePooling2D`**  \n","Reduce cada mapa de caracter√≠sticas a un √∫nico valor promedio.  \n","Disminuye dr√°sticamente el n√∫mero de par√°metros y ayuda a evitar sobreentrenamiento.\n","\n","**8. `include_top=False`**  \n","Indica que no se utiliza la parte final del modelo preentrenado (clasificador original de ImageNet).  \n","Permite agregar un clasificador propio para un nuevo conjunto de clases.\n"],"metadata":{"id":"Lhav0vQ8AR_e"},"id":"Lhav0vQ8AR_e"},{"cell_type":"markdown","id":"de3a18d4","metadata":{"id":"de3a18d4"},"source":["\n","## ¬øEfficientNetB0 es una CNN?\n","\n","S√≠. EfficientNetB0 es una red neuronal convolucional (CNN), igual que la que construimos en la Parte 1.  \n","La diferencia es que EfficientNetB0 es **mucho m√°s profunda y compleja**, e incluye:\n","- decenas de capas convolucionales,\n","- capas avanzadas como MBConv y SE blocks,\n","- normalizaci√≥n,\n","- etapas de reducci√≥n progresiva del tama√±o espacial.\n","\n","En esta actividad no analizamos cada capa internamente (ser√≠a demasiado complejo), sino que\n","utilizamos EfficientNetB0 como **modelo preentrenado** para aplicar Transfer Learning.\n"]},{"cell_type":"markdown","source":["## Nota importante: ¬øQu√© hace realmente EfficientNetB0?\n","\n","En la actividad anterior, usted utiliz√≥ **MobileNetV2** para clasificar im√°genes reales de su computador.  \n","Gracias a eso, pudo observar directamente:\n","\n","- las predicciones del modelo,  \n","- los aciertos y errores,  \n","- los patrones que reconoce,  \n","- y los sesgos que pueden aparecer.\n","\n","En esta segunda parte, el objetivo es distinto:  \n","**no buscamos volver a clasificar im√°genes**, sino comprender la estructura interna de un modelo moderno, **EfficientNetB0**, y explorar algunos de sus hiperpar√°metros clave.\n","\n","**EfficientNetB0** es tambi√©n una **red neuronal convolucional (CNN)**, igual que **MobileNetV2**, pero mucho m√°s profunda y compleja.  \n","Aqu√≠ nos enfocamos en:\n","\n","- c√≥mo est√° construida su base convolucional,\n","- qu√© significa congelar o descongelar capas,\n","- c√≥mo influyen hiperpar√°metros como `input_shape`, `dropout` o `learning_rate`,\n","- y c√≥mo estos cambios afectan el proceso de entrenamiento.\n","\n","Si aun as√≠ desea **comprobar que EfficientNetB0 puede clasificar im√°genes reales**, tal como lo hizo MobileNetV2, puede hacerlo ejecutando la celda de c√≥digo que se encuentra m√°s abajo.  \n","Esa celda permite cargar una imagen desde su computador y obtener una predicci√≥n con el modelo que acaba de construir.\n"],"metadata":{"id":"5-GRamZfftjt"},"id":"5-GRamZfftjt"},{"cell_type":"markdown","source":["```python\n","# ================================================\n","# CLASIFICAR IM√ÅGENES REALES CON EfficientNetB0\n","# ================================================\n","\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","from google.colab import files\n","import matplotlib.pyplot as plt\n","\n","# 1. Subir imagen desde el computador\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","    img_path = fn\n","    print(\"Imagen cargada:\", fn)\n","\n","    # 2. Cargar y preprocesar la imagen\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","\n","    # 3. Mostrar imagen cargada\n","    plt.imshow(image.load_img(img_path))\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    # 4. Obtener predicci√≥n (probabilidades)\n","    pred = modelo_eff.predict(x)\n","    print(\"\\nVector de probabilidades:\", pred)\n","\n","    # 5. Mostrar la clase predicha\n","    pred_class = np.argmax(pred)\n","    print(f\"\\nClase predicha: {pred_class}\")\n"],"metadata":{"id":"TaMxti5ngJbO"},"id":"TaMxti5ngJbO"},{"cell_type":"markdown","source":["Si opto por clasificar imagenes, lo mas probable es que las siguientes preguntas lo respresenten en un 100%:\n","* ¬øPor qu√© esta CNN tiene solo 5 clases?\n","* ¬øC√≥mo se interpreta el vector de probabilidades?\n","\n","En esta actividad, la capa final de **EfficientNetB0** fue definida as√≠:\n","\n","```python\n","outputs = layers.Dense(5, activation=\"softmax\")(x)\n","```\n","Esto significa que hemos creado un clasificador con 5 categor√≠as posibles.\n","El modelo no conoce los nombres reales de esas clases (por ejemplo ‚Äúperro‚Äù, ‚Äúauto‚Äù, etc.).\n","Solo sabe que debe asignar una probabilidad a cada una de las 5 clases numeradas:\n","* Clase 0\n","* Clase 1\n","* Clase 2\n","* Clase 3\n","* Clase 4"],"metadata":{"id":"4I7rl6mGh3ii"},"id":"4I7rl6mGh3ii"},{"cell_type":"markdown","source":["Ahora bien, cuando ejecutamos:\n","```python\n","pred = modelo_eff.predict(x)\n","```\n","obtendremos un vector como:\n","```python\n","[0.02, 0.65, 0.10, 0.20, 0.03]\n","```\n","Cada n√∫mero representa la probabilidad estimada de que la imagen pertenezca a una de las clases:\n","* 0.02 : probabilidad de ser clase 0\n","* 0.65 : probabilidad de ser clase 1\n","* 0.10 : probabilidad de ser clase 2\n","* 0.20 : probabilidad de ser clase 3\n","* 0.03 : probabilidad de ser clase 4\n","\n","La clase predicha es aquella con la probabilidad m√°s alta:\n","```python\n","np.argmax(pred)   # en este caso, 1\n","```\n","Es decir, el modelo clasifica la imagen como clase 1."],"metadata":{"id":"MpEw-dvMiobv"},"id":"MpEw-dvMiobv"}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["e4cf59d6","lFJQNPNpAurJ","ZylpuaKTAjqz"],"toc_visible":true},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}